{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.distributions import Categorical, kl\n",
    "# from d2l.torch import Animator\n",
    "\n",
    "from net import Net\n",
    "from aco import ACO\n",
    "from utils import gen_pyg_data, load_val_dataset\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "lr = 3e-4\n",
    "EPS = 1e-10\n",
    "T=5\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_instance(model, optimizer, pyg_data, distances, n_ants):\n",
    "    model.train()\n",
    "    heu_vec = model(pyg_data)\n",
    "    heu_mat = model.reshape(pyg_data, heu_vec) + EPS\n",
    "    \n",
    "    aco = ACO(\n",
    "        n_ants=n_ants,\n",
    "        heuristic=heu_mat,\n",
    "        distances=distances,\n",
    "        device=device\n",
    "        )\n",
    "    \n",
    "    costs, log_probs, _ = aco.sample()\n",
    "    baseline = costs.mean()\n",
    "    reinforce_loss = torch.sum((costs - baseline) * log_probs.sum(dim=0)) / aco.n_ants\n",
    "    optimizer.zero_grad()\n",
    "    reinforce_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def infer_instance(model, pyg_data, distances, n_ants):\n",
    "    model.eval()\n",
    "    heu_vec = model(pyg_data)\n",
    "    heu_mat = model.reshape(pyg_data, heu_vec) + EPS\n",
    "    aco = ACO(\n",
    "        n_ants=n_ants,\n",
    "        heuristic=heu_mat,\n",
    "        distances=distances,\n",
    "        device=device\n",
    "        )\n",
    "    costs, log_probs, _ = aco.sample()\n",
    "    aco.run(n_iterations=T)\n",
    "    baseline = costs.mean().item()\n",
    "    best_sample_cost = torch.min(costs).item()\n",
    "    best_aco_cost = aco.lowest_cost\n",
    "    return baseline, best_sample_cost, best_aco_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(n_node,\n",
    "                n_ants, \n",
    "                k_sparse, \n",
    "                epoch, \n",
    "                steps_per_epoch, \n",
    "                net, \n",
    "                optimizer\n",
    "                ):\n",
    "    for _ in range(steps_per_epoch):\n",
    "        instance = torch.rand(size=(n_node, 2), device=device)\n",
    "        data, distances = gen_pyg_data(instance, k_sparse=k_sparse)\n",
    "        train_instance(net, optimizer, data, distances, n_ants)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation(n_ants, epoch, net, val_dataset, animator=None):\n",
    "    sum_bl, sum_sample_best, sum_aco_best = 0, 0, 0\n",
    "    \n",
    "    for data, distances in val_dataset:\n",
    "        bl, sample_best, aco_best = infer_instance(net, data, distances, n_ants)\n",
    "        sum_bl += bl; sum_sample_best += sample_best; sum_aco_best += aco_best\n",
    "    \n",
    "    n_val = len(val_dataset)\n",
    "    avg_bl, avg_sample_best, avg_aco_best = sum_bl/n_val, sum_sample_best/n_val, sum_aco_best/n_val\n",
    "    # if animator:\n",
    "    #     animator.add(epoch+1, (avg_bl, avg_sample_best, avg_aco_best))\n",
    "    \n",
    "    return avg_bl, avg_sample_best, avg_aco_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_node, k_sparse, n_ants, steps_per_epoch, epochs):\n",
    "    net = net = Net(gfn=False).to(device)\n",
    "    optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "    val_list = load_val_dataset(n_node, k_sparse, device)\n",
    "    animator = None # Animator(xlabel='epoch', xlim=[0, epochs], legend=[\"Avg. sample obj.\", \"Best sample obj.\", \"Best ACO obj.\"])\n",
    "    \n",
    "    avg_bl, avg_best, avg_aco_best = validation(n_ants, -1, net, val_list, animator)\n",
    "    val_results = [(avg_bl, avg_best, avg_aco_best)]\n",
    "    \n",
    "    sum_time = 0\n",
    "    for epoch in range(0, epochs):\n",
    "        start = time.time()\n",
    "        train_epoch(n_node, n_ants, k_sparse, epoch, steps_per_epoch, net, optimizer)\n",
    "        sum_time += time.time() - start\n",
    "        avg_bl, avg_sample_best, avg_aco_best = validation(n_ants, epoch, net, val_list, animator)\n",
    "        val_results.append((avg_bl, avg_sample_best, avg_aco_best))\n",
    "        \n",
    "    print('total training duration:', sum_time)\n",
    "    \n",
    "    for epoch in range(-1, epochs):\n",
    "        print(f'epoch {epoch}:', val_results[epoch+1])\n",
    "        \n",
    "    # torch.save(net.state_dict(), f'../pretrained/tsp/tsp{n_node}.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn heuristic for TSP20: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training duration: 15.017478466033936\n",
      "epoch -1: (7.513315134048462, 6.231752462387085, 3.787857837677002)\n",
      "epoch 0: (4.83945333480835, 4.096140575408936, 3.7878578519821167)\n",
      "epoch 1: (4.378843965530396, 3.8765585231781006, 3.787857856750488)\n",
      "epoch 2: (4.27893536567688, 3.8807146167755127, 3.787857871055603)\n",
      "epoch 3: (4.321380271911621, 3.8742052698135376, 3.78785786151886)\n",
      "epoch 4: (4.3237948513031, 3.8907668447494506, 3.78785786151886)\n"
     ]
    }
   ],
   "source": [
    "n_node, n_ants = 20, 20\n",
    "k_sparse = 10\n",
    "steps_per_epoch = 128\n",
    "epochs = 5\n",
    "train(n_node, k_sparse, n_ants, steps_per_epoch, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn heuristic for TSP100: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training duration: 43.585044622421265\n",
      "epoch -1: (21.311012954711913, 19.63759094238281, 7.8251377201080325)\n",
      "epoch 0: (11.352936344146729, 10.460236339569091, 7.7966246414184575)\n",
      "epoch 1: (9.84587589263916, 9.101685390472412, 7.78905686378479)\n",
      "epoch 2: (9.694465713500977, 9.044547328948974, 7.796471109390259)\n",
      "epoch 3: (9.640990810394287, 8.939566841125488, 7.793552856445313)\n",
      "epoch 4: (9.665411338806152, 8.979426040649415, 7.786292972564698)\n"
     ]
    }
   ],
   "source": [
    "n_node = 100\n",
    "n_ants = 20\n",
    "k_sparse = 20\n",
    "steps_per_epoch = 128\n",
    "epochs = 5\n",
    "train(n_node, k_sparse, n_ants, steps_per_epoch, epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn heuristic for TSP500: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node = 500\n",
    "n_ants = 50\n",
    "k_sparse = 50\n",
    "steps_per_epoch = 128\n",
    "epochs = 5\n",
    "train(n_node, k_sparse, n_ants, steps_per_epoch, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "H-DGACO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
